# -*- coding: utf-8 -*-
"""COSC.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Hk4cvOEb9OyFrUuhZlMiTp8isAm6cATr
"""

!pip install pytesseract opencv-python-headless Pillow

!apt-get install -y tesseract-ocr

import cv2
import pytesseract
from google.colab import files
import numpy as np

# Upload an image file
uploaded = files.upload()

# Get the uploaded file name
image_path = next(iter(uploaded))
print(f"Uploaded image path: {image_path}")

def preprocess_image(uploaded_image):
    # Load the image from the uploaded file
    image = cv2.imdecode(np.frombuffer(uploaded[uploaded_image], np.uint8), cv2.IMREAD_COLOR)

    # Convert to grayscale
    gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
    # Apply GaussianBlur to reduce noise and improve OCR accuracy
    blurred_image = cv2.GaussianBlur(gray_image, (5, 5), 0)
    # Thresholding to get binary image
    _, binary_image = cv2.threshold(blurred_image, 150, 255, cv2.THRESH_BINARY_INV)
    return binary_image

def extract_text(image):
    # Use pytesseract to do OCR on the preprocessed image
    extracted_text = pytesseract.image_to_string(image)
    return extracted_text

def extract_data(text):
    name = ""
    income = 0
    lines = text.split('\n')

    for line in lines:
        if "Name:" in line:
            name = line.split("Name:")[1].strip()
        elif "Annual Income:" in line:
            income_str = line.split("Annual Income:")[1].strip()
            income = int(income_str.replace(',', ''))

    return name, income

def validate_income(income, threshold=200000):
    return income > threshold

def process_income_certificate(uploaded_image):
    preprocessed_image = preprocess_image(uploaded_image)
    extracted_text = extract_text(preprocessed_image)
    print("Extracted Text:", extracted_text)

    name, income = extract_data(extracted_text)

    print(f"Name: {name}")
    print(f"Annual Income: {income}")

    if validate_income(income):
        print("Income validation successful: Income is greater than 200,000.")
    else:
        print("Income validation failed: Income is not greater than 200,000.")

# Step 1: Install Necessary Libraries
!apt-get install -y tesseract-ocr
!apt-get install -y libtesseract-dev
!pip install pytesseract
!pip install opencv-python pillow

# Step 2: Import Libraries and Set Up Tesseract Path
import pytesseract
import cv2
import re
from google.colab import files

# Set up Tesseract path (optional in Colab as it's installed globally)
pytesseract.pytesseract.tesseract_cmd = "/usr/bin/tesseract"

# Step 3: Upload Files (Images)
uploaded = files.upload()

# Step 4: Image Processing and Text Extraction
def preprocess_image(image_path):
    # Load the image using OpenCV
    img_cv = cv2.imread(image_path)

    # Convert to grayscale
    img_gray = cv2.cvtColor(img_cv, cv2.COLOR_BGR2GRAY)

    # Apply Gaussian blur to reduce noise
    img_blur = cv2.GaussianBlur(img_gray, (5, 5), 0)

    # Apply adaptive thresholding for better contrast
    img_thresh = cv2.adaptiveThreshold(img_blur, 255,
                                       cv2.ADAPTIVE_THRESH_GAUSSIAN_C,
                                       cv2.THRESH_BINARY, 11, 2)

    # Dilation to strengthen text areas
    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (3, 3))
    img_dilated = cv2.dilate(img_thresh, kernel, iterations=1)

    return img_dilated

def extract_text_from_image(image_path):
    img_processed = preprocess_image(image_path)

    # Use Tesseract to extract text from the processed image
    text = pytesseract.image_to_string(img_processed, config='--psm 6')

    return text

# Step 5: Extract Information Using Robust Regular Expressions
def extract_info(text):
    info = {}

    # Roll Number pattern (12 digits)
    roll_number_pattern = r"Roll\s*No[-:]*\s*(\d{12})"
    roll_number_match = re.search(roll_number_pattern, text, re.IGNORECASE)
    info['Roll Number'] = roll_number_match.group(1) if roll_number_match else "Not found"

    # Name pattern (assuming it follows 'Name : ')
    name_pattern = r"Name\s*[-:]*\s*([A-Z\s]+)"
    name_match = re.search(name_pattern, text, re.IGNORECASE)
    info['Name'] = name_match.group(1).strip() if name_match else "Not found"

    # Father's Name pattern (assuming it follows 'Father Name : ')
    father_name_pattern = r"Father Name\s*[-:]*\s*([A-Z\s]+)"
    father_name_match = re.search(father_name_pattern, text, re.IGNORECASE)
    info['Father Name'] = father_name_match.group(1).strip() if father_name_match else "Not found"

    # Course pattern (assuming it follows 'Course : ')
    course_pattern = r"Course\s*[-:]*\s*([A-Z\.\s\(\)]+)"
    course_match = re.search(course_pattern, text, re.IGNORECASE)
    info['Course'] = course_match.group(1).strip() if course_match else "Not found"

    # Date of Birth pattern (if applicable)
    dob_pattern = r"\b\d{2}/\d{2}/\d{4}\b"  # Placeholder for DOB extraction
    dob_match = re.search(dob_pattern, text)
    info['Date of Birth'] = dob_match.group() if dob_match else "Not found"

    return info

# Step 6: Process Uploaded Files
for filename in uploaded.keys():
    extracted_text = extract_text_from_image(filename)
    print(f"Extracted Text from {filename}:\n", extracted_text)

    # Extract information
    extracted_info = extract_info(extracted_text)

    # Print formatted output
    print(f"Extracted Information from {filename}:")
    for key, value in extracted_info.items():
        print(f"{key}: {value}")

pip install google-cloud-vision

pip install google-cloud-vision

import google.cloud.vision

import cv2
import numpy as np

# Function to preprocess an image
def preprocess_image(image_path):
    # Read the image using OpenCV
    image = cv2.imread(image_path)

    # Resize the image to 192x192
    resized_image = cv2.resize(image, (192, 192))

    # Normalize the pixel values to range [0, 1]
    normalized_image = resized_image / 255.0

    return normalized_image

# Example usage
image_path = '/content/CBIT ID CARD PIC (1).png'
processed_image = preprocess_image(image_path)

print(processed_image.shape)  # Output will be (192, 192, 3)



import requests

def extract_text_from_image(image_path, api_key):
    url = "https://api.ocr.space/parse/image"

    # Open the image file
    with open(image_path, 'rb') as image_file:
        # Prepare the payload
        payload = {
            'apikey': api_key,
            'language': 'eng',  # Set the language; can be 'eng', 'deu', 'fra', etc.
            'isOverlayRequired': False,
        }

        # Make a request to the API
        response = requests.post(url, files={'filename': image_file}, data=payload)

        # Check if the request was successful
        if response.status_code == 200:
            result = response.json()
            # Extract the text from the result
            if 'ParsedResults' in result:
                return result['ParsedResults'][0]['ParsedText']
            else:
                return "No text found in the image."
        else:
            return f"Error: {response.status_code} - {response.text}"

# Example usage
if __name__ == "__main__":
    # Replace with your OCR.Space API key
    API_KEY = "K86901321688957"

    # Replace with the path to your image file
    IMAGE_PATH = "/content/CBIT ID CARD PIC (1).png"

    extracted_text = extract_text_from_image(IMAGE_PATH, API_KEY)
    print("Extracted Text:")
    print(extracted_text)

import requests

# Function to extract text from image using OCR.Space API
def extract_text_from_image(image_path, api_key):
    url = "https://api.ocr.space/parse/image"

    # Open the image file
    with open(image_path, 'rb') as image_file:
        # Prepare the payload
        payload = {
            'apikey': api_key,
            'language': 'eng',  # Set the language; can be 'eng', 'deu', 'fra', etc.
            'isOverlayRequired': False,
        }

        # Make a request to the API
        response = requests.post(url, files={'filename': image_file}, data=payload)

        # Check if the request was successful
        if response.status_code == 200:
            result = response.json()
            # Extract the text from the result
            if 'ParsedResults' in result:
                return result['ParsedResults'][0]['ParsedText']
            else:
                return "No text found in the image."
        else:
            return f"Error: {response.status_code} - {response.text}"

# Function to verify roll number
def verify_roll_number(roll_number):
    if len(roll_number) > 12 or roll_number.isdigit():
        return True
    return False

# Example usage
if __name__ == "__main__":
    # Replace with your OCR.Space API key
    API_KEY = "K86901321688957"

    # Replace with the path to your image file
    IMAGE_PATH = "/content/CBIT ID CARD PIC (1).png"

    # Extract text from image
    extracted_text = extract_text_from_image(IMAGE_PATH, API_KEY)
    print("Extracted Text:")
    print(extracted_text)

    # Try to find a roll number in the extracted text
    # Assuming the roll number is part of the extracted text
    roll_number = extracted_text.strip()  # Adjust according to the format of extracted data

    # Verify the extracted roll number
    if verify_roll_number(roll_number):
        print("Roll number is valid.")
    else:
        print("Roll number is invalid.")

